<div
  style={{
    maxWidth: '900px',
    margin: '2.5rem auto',
    padding: '2rem 1.5rem',
    background: '#fff',
    borderRadius: '12px',
    boxShadow: '0 2px 8px #0001',
    fontFamily: 'Segoe UI, Tahoma, Geneva, Verdana, sans-serif',
    lineHeight: '1.6',
    color: '#333'
  }}
>

# üß† Shared Tasks @ SLT4LRL 2025 ‚Äì Sign Language

> ‚ö†Ô∏è **Interested in participating?**  
> Join our [Discord server](https://discord.gg/jGRFg3YV) to stay updated and connect with other participants!

## üßæ Call for Shared Tasks

**SLT4LRL 2025: Workshop on Sign Language Translation**

- üìç *Co-located with IJCNLP-AACL 2025*
- üìÖ *Date: TBD*
- üìç *Victor Menezes Convention Centre (VMCC), IIT Bombay, Mumbai, India*

SLT4LRL 2025 invites participants to three **Shared Tasks** addressing key challenges in **Indian Sign Language (ISL) processing**.

## üîç Shared Tasks Overview

| Task # | Name                        | Focus                                            | Dataset                                                                 |
|--------|-----------------------------|--------------------------------------------------|-------------------------------------------------------------------------|
| Task 1 | ISL to English Translation   | Sentence-level translation from ISL videos/pose to English | [iSign](https://huggingface.co/datasets/Exploration-Lab/iSign)          |
| Task 2 | Word/Gloss Recognition      | Isolated sign recognition at the word level       | [CISLR](https://huggingface.co/datasets/Exploration-Lab/CISLR)          |
| Task 3 | Word Presence Prediction    | Detecting presence of a word in a signed sentence | [Word Presence Dataset](https://huggingface.co/datasets/Exploration-Lab/iSign/viewer/word-presence-dataset_v1.1?views%5B%5D=word_presence_dataset_v11) |

## üìã Shared Tasks Details

### üåê Task 1: ISL to English Translation

**Goal:** Translate sentence-level Indian Sign Language (ISL) videos/poses into English text.

- **Challenges:** Visual-linguistic grounding, grammar, gesture ambiguity
- **Use Cases:** Sign-enabled chatbots, video interpreters, accessible interfaces
- **Dataset:** [iSign](https://huggingface.co/datasets/Exploration-Lab/iSign) (118,000 video-sentence pairs)
- **Metrics:** BLEU, ROUGE, chrF
- **Input ‚ûù Output:** ISL video/pose ‚ûù English sentence

<div style={{ display: 'flex', flexWrap: 'wrap', gap: '2rem', justifyContent: 'center', margin: '2rem 0' }}>
  <div style={{ flex: '0 1 300px' }}>
    <video
      autoplay
      muted
      loop
      playsinline
      style={{ width: '300px', height: '200px', objectFit: 'cover', borderRadius: '4px', border: '1px solid #000' }}
    >
      <source src="/SLT/The_ban_would_mean_she_can't_compete_in_any_national_or_other_domestic_events.mp4" type="video/mp4" />
    </video>
    <div style={{ marginTop: '0.75rem', fontSize: '0.9rem', color: '#666' }}>
      <strong>English Translation:</strong> "The ban would mean she can't compete in any national or other domestic events"
    </div>
  </div>
</div>

<div style={{ display: 'flex', flexWrap: 'wrap', gap: '10px', marginTop: '1.5rem' }}>
  <a href="https://huggingface.co/datasets/Exploration-Lab/iSign" target="_blank" style={{ padding: '8px 16px', backgroundColor: 'white', color: '#0a0a0a', textDecoration: 'none', borderRadius: '4px', fontSize: '0.9rem', border: '1px solid #0a0a0a', transition: 'all 0.2s ease' }}>
    iSign Dataset
  </a>
  <a href="#" target="_blank" style={{ padding: '8px 16px', backgroundColor: 'white', color: '#0a0a0a', textDecoration: 'none', borderRadius: '4px', fontSize: '0.9rem', border: '1px solid #0a0a0a', transition: 'all 0.2s ease' }}>
    CodaLab (Coming Soon)
  </a>
</div>

---

### ‚úã Task 2: Word/Gloss Recognition

**Goal:** Recognize isolated ISL signs (words or glosses) from short video clips.

- **Challenges:** Sign variability, subtle motion, similar gestures
- **Use Cases:** Dictionary building, lookup tools, annotation
- **Dataset:** [CISLR](https://huggingface.co/datasets/Exploration-Lab/CISLR) (7,050 labeled video clips)
- **Metrics:** Accuracy, Top-K Accuracy
- **Input ‚ûù Output:** Video clip ‚ûù Word label

<div style={{ display: 'flex', flexWrap: 'wrap', gap: '2rem', justifyContent: 'center', margin: '2rem 0' }}>
  <div style={{ flex: '0 1 300px' }}>
    <video
      autoplay
      muted
      loop
      playsinline
      style={{ width: '300px', height: '200px', objectFit: 'cover', borderRadius: '4px', border: '1px solid #000' }}
    >
      <source src="/SLT/National_(Sign_2).mp4" type="video/mp4" />
    </video>
    <div style={{ marginTop: '0.75rem', fontSize: '0.9rem', color: '#666' }}>
      <strong>Label:</strong> "National"
    </div>
  </div>
</div>

<div style={{ display: 'flex', flexWrap: 'wrap', gap: '10px', marginTop: '1.5rem' }}>
  <a href="https://huggingface.co/datasets/Exploration-Lab/CISLR" target="_blank" style={{ padding: '8px 16px', backgroundColor: 'white', color: '#0a0a0a', textDecoration: 'none', borderRadius: '4px', fontSize: '0.9rem', border: '1px solid #0a0a0a', transition: 'all 0.2s ease' }}>
    CISLR Dataset
  </a>
  <a href="#" target="_blank" style={{ padding: '8px 16px', backgroundColor: 'white', color: '#0a0a0a', textDecoration: 'none', borderRadius: '4px', fontSize: '0.9rem', border: '1px solid #0a0a0a', transition: 'all 0.2s ease' }}>
    CodaLab (Coming Soon)
  </a>
</div>

---

### üîç Task 3: Word Presence Prediction

**Goal:** Predict if a given word is present in a full ISL sentence video.

- **Challenges:** Sign spotting, context alignment
- **Use Cases:** Query-based video retrieval, sign search
- **Dataset:** [Word Presence Dataset](https://huggingface.co/datasets/Exploration-Lab/iSign/viewer/word-presence-dataset_v1.1?views%5B%5D=word_presence_dataset_v11) (1,543 video-query pairs)
- **Metrics:** Accuracy, Precision, Recall, F1
- **Input ‚ûù Output:** (Video, Word) ‚ûù Present / Not Present

<div style={{ display: 'flex', flexWrap: 'wrap', gap: '2rem', justifyContent: 'center', margin: '2rem 0' }}>
  <div style={{ flex: '0 1 300px' }}>
    <video
      autoplay
      muted
      loop
      playsinline
      style={{ width: '300px', height: '200px', objectFit: 'cover', borderRadius: '4px', border: '1px solid #000' }}
    >
      <source src="/SLT/National_(Sign_2).mp4" type="video/mp4" />
    </video>
    <div style={{ marginTop: '0.75rem', fontSize: '0.9rem', color: '#666' }}>
      Query Word: "National"
    </div>
  </div>
  <div style={{ flex: '0 1 300px' }}>
    <video
      autoplay
      muted
      loop
      playsinline
      style={{ width: '300px', height: '200px', objectFit: 'cover', borderRadius: '4px', border: '1px solid #000' }}
    >
      <source src="/SLT/The_ban_would_mean_she_can't_compete_in_any_national_or_other_domestic_events.mp4" type="video/mp4" />
    </video>
    <div style={{ marginTop: '0.75rem', fontSize: '0.9rem', color: '#666' }}>
      Sentence Video: "The ban would mean she can't compete in any national or other domestic events" contains: "National"
    </div>
  </div>
</div>

<div style={{ display: 'flex', flexWrap: 'wrap', gap: '10px', marginTop: '1.5rem' }}>
  <a href="https://huggingface.co/datasets/Exploration-Lab/iSign/viewer/word-presence-dataset_v1.1?views%5B%5D=word_presence_dataset_v11" target="_blank" style={{ padding: '8px 16px', backgroundColor: 'white', color: '#0a0a0a', textDecoration: 'none', borderRadius: '4px', fontSize: '0.9rem', border: '1px solid #0a0a0a', transition: 'all 0.2s ease' }}>
    Word Presence Dataset
  </a>
  <a href="#" target="_blank" style={{ padding: '8px 16px', backgroundColor: 'white', color: '#0a0a0a', textDecoration: 'none', borderRadius: '4px', fontSize: '0.9rem', border: '1px solid #0a0a0a', transition: 'all 0.2s ease' }}>
    CodaLab (Coming Soon)
  </a>
</div>

---

## üóì Key Dates

| Event                        | Date                          |
|------------------------------|-------------------------------|
| üü¢ Start Date               | July 20, 2025                  |
| üìö Training Phase           | July 20 ‚Äì October 5, 2025      |
| üß™ Testing Phase            | October 5 ‚Äì October 15, 2025 |
| üìÑ Paper Submission Deadline| October 25, 2025            |
| üì¨ Notification of Acceptance| November 3, 2025              |
| üì∏ Camera-ready Papers Due  | November 11, 2025             |
| üìö Proceedings Due          | December 1, 2025              |

## üë• Call for Participation

We invite **researchers**, **students**, and **developers** in **computer vision**, **natural language processing**, **speech and gesture technology**, or related fields to participate. Contribute to building inclusive tools for millions of ISL users.

**Contact Organizers:**
- **Ashutosh Modi**: [ashutoshm@cse.iitk.ac.in](mailto:ashutoshm@cse.iitk.ac.in)
- **Abhinav Joshi**: [ajoshi@cse.iitk.ac.in](mailto:ajoshi@cse.iitk.ac.in)
- **Sanjeet Singh**: [sanjeet@cse.iitk.ac.in](mailto:sanjeet@cse.iitk.ac.in)

## üì¶ Submission Guidelines

- **Platform:** CodaLab (links coming soon)
- **Team Size:** Max 4 members (TBD)
- **Format:** To be released with dataset
- **Requirements:** Output on test set + short documentation
- **Paper Submission:** Full (8 pages) or short (4 pages) papers, following [ACL Style](https://github.com/acl-org/acl-style-files). Double-blind review. Accepted papers get +1 page for revisions.

## üèÜ Awards & Prizes

| üèÖ Rank | Prize (INR) |
|---------|-------------|
| ü•á 1st  | XXX INR     |
| ü•à 2nd  | XXX INR     |
| ü•â 3rd  | XXX INR     |

> ‚úÖ **Get ready** to build impactful AI tools for the Deaf community. Stay tuned for dataset releases and CodaLab instructions!

</div>